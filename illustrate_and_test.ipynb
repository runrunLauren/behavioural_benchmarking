{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:17.607042Z",
     "start_time": "2024-09-18T11:06:16.843857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from behavioural_benchmark.indicators import MemoisedIndicators\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import os\n",
    "import random"
   ],
   "id": "243a01969aa27300",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To test and illustrate the indicators, let's construct examples where we know the answers. For each indicator we will create some data where we decide on the values of the indicators, and at the end we will assert that the calculated indicators match up with the expected ones.\n",
    "\n",
    "## Regression indicators\n",
    "\n",
    "For the regression based indicators, we can define graphs of two lines with set gradients. We can sample points along these lines, and save these to a file. Then later we can assert whether the regression indicators confirm the gradients we selected."
   ],
   "id": "1bd7cbd1746b94f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:17.613783Z",
     "start_time": "2024-09-18T11:06:17.608072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = 100\n",
    "x = np.array([j for j in range(0,100,2)])\n",
    "\n",
    "def sample_points(m_1, m_2):\n",
    "    y_1 = m_1 * x + c\n",
    "    c_2 = y_1[floor(0.70 * len(y_1[y_1 >= 0]))]\n",
    "    x_1 = x[y_1 >= c_2]\n",
    "    y_1 = y_1[y_1 >= c_2]\n",
    "\n",
    "    y_2 = m_2 * (x_1 + 1) + c_2\n",
    "    x_2 = x_1 + max(x_1) + 1\n",
    "    x_2 = x_2[y_2 >= 0]\n",
    "    y_2 = y_2[y_2 >= 0]\n",
    "    \n",
    "    return np.concat([x_1, x_2]), np.concat([y_1, y_2]), max(x_1), c_2\n",
    "\n",
    "def save_to_file(xf, yf, filename):\n",
    "    data = np.column_stack((xf, yf))\n",
    "    np.savetxt(f\"example_data/{filename}.csv\", data, delimiter=\",\", header=f\"iteration,{filename}\", comments=\"\", fmt=\"%.4f\")\n",
    "\n",
    "# diversity\n",
    "DRoC_A = -2\n",
    "DRoC_B = -0.9\n",
    "diversity_x, diversity_y, ERT_Diversity, Critical_Diversity = sample_points(DRoC_A, DRoC_B)\n",
    "save_to_file(diversity_x, diversity_y, \"diversity\")\n",
    "\n",
    "# fitness\n",
    "FRoC_A = -1.8\n",
    "FRoC_B = -1.0\n",
    "fitness_x, fitness_y, ERT_Fitness, Critical_Fitness = sample_points(FRoC_A, FRoC_B)\n",
    "save_to_file(fitness_x, fitness_y, \"fitness\")\n",
    "\n",
    "# distance\n",
    "SRoC_A = -2.05\n",
    "SRoC_B = -0.75\n",
    "distance_x, distance_y, ERT_Separation, Critical_Separation = sample_points(SRoC_A, SRoC_B)\n",
    "save_to_file(distance_x, distance_y, \"distance\")\n",
    "\n",
    "# Mobility\n",
    "MRoC_A = -1.05\n",
    "MRoC_B = -1.0\n",
    "mobility_x, mobility_y, ERT_Mobility, Critical_Mobility = sample_points(MRoC_A, MRoC_B)\n",
    "save_to_file(mobility_x, mobility_y, \"mobility\")"
   ],
   "id": "389b200dccc3240a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For the network based indicators, we need to construct interaction data, and trajectory data.\n",
    "\n",
    "## Trajectory indicators\n",
    "\n",
    "For the trajectory data, we can decide on a number of nodes and shared nodes. We can then simulate trajectories between these nodes, making sure that every node is visited at least once. We can create two runs, with shared nodes appearing in both runs. We can arbitrarily set the fitness of each node equal to 0, as it's not required for the indicators we are testing."
   ],
   "id": "a93781780a8e311a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:17.741617Z",
     "start_time": "2024-09-18T11:06:17.734887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# STN\n",
    "shared_nodes = list(range(20, 30))\n",
    "nodes = {\n",
    "    0: list(range(20)) + shared_nodes,\n",
    "    1: shared_nodes + list(range(30, 30+20))\n",
    "}\n",
    "nbest = 5\n",
    "best_nodes = random.sample(nodes[0] + nodes[1], nbest)\n",
    "ntotal = len(np.unique(nodes[0] + nodes[1]))\n",
    "nshared = len(shared_nodes)\n",
    "best_strength = 0\n",
    "\n",
    "file  = \"example_data/stn.csv\"\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "with open(file, \"w\") as f:\n",
    "    f.write(\"Run,Fitness1,Solution1,Fitness2,Solution2\\n\")\n",
    "    for run in [0,1]:\n",
    "        current_position = dict(zip(range(10), random.sample(nodes[run], 10)))\n",
    "        \n",
    "        # Create a set of nodes to ensure each one is selected at least once\n",
    "        required_nodes = set(nodes[run])\n",
    "        selected_nodes = set(current_position.values())  # Keep track of selected nodes\n",
    "        for _step in range(10):\n",
    "            for individual in range(10):\n",
    "                # Ensure each node is selected at least once\n",
    "                if len(selected_nodes) < len(required_nodes):\n",
    "                    # Pick a node from the unselected ones\n",
    "                    next_position = random.choice(list(required_nodes - selected_nodes))\n",
    "                    selected_nodes.add(next_position)\n",
    "                else:\n",
    "                    # Once all nodes have been selected at least once, continue with random choice\n",
    "                    next_position = random.choice(nodes[run])\n",
    "                if current_position[individual] in best_nodes:\n",
    "                    current_fitness = 0\n",
    "                else:\n",
    "                    current_fitness = 1\n",
    "                if next_position in best_nodes:\n",
    "                    best_strength += 1\n",
    "                    next_fitness = 0\n",
    "                else:\n",
    "                    next_fitness = 1\n",
    "                f.write(f\"{run},{current_fitness},{current_position[individual]},{next_fitness},{next_position}\\n\")\n",
    "                current_position[individual] = next_position\n",
    "best_strength /= 2  # number of runs"
   ],
   "id": "1e15c9762861521b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Interaction  indicators\n",
    "\n",
    "For the interaction data, we can create a small network of 5 individuals, resulting in a 5 x 5 grid. We can choose an IDRoC, and then model the interactions to result in the chosen IDRoC. We can also make sure the solution node has a weight equal to some chosen ISS."
   ],
   "id": "798bb957f0d80ce7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:18.075321Z",
     "start_time": "2024-09-18T11:06:18.070518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# IN\n",
    "MID = (1 + 2 + 3 + 5) / 4\n",
    "MGC = (5 + 3 + 2 + 1) / 4 / 5  #  dividing by 5 normalises this, which is how it appears in their paper \n",
    "solution_index = 3\n",
    "SNID = 30 / (2 * 10)\n",
    "\n",
    "# let number of subgraphs be of 1, 2, 3, 5 (y)\n",
    "# let size of subgraphs be 5, 3, 2, 1\n",
    "# with maximum edge_weight removed equal to 0.0, 0.25, 0.5, 1.0 (x)\n",
    "# (5 - 1) / (1.0 - 0.0) = 4\n",
    "\n",
    "arr = np.array([\n",
    "    # 0   1   2   3   4\n",
    "    [ 0, 20,  0,  0,  0], # 0\n",
    "    [20,  0,  5,  0,  0], # 1\n",
    "    [ 0,  5,  0, 10,  0], # 2\n",
    "    [ 0,  0, 10,  0, 20], # 3\n",
    "    [ 0,  0,  0, 20,  0]  # 4\n",
    "])\n",
    "\n",
    "zeroes = np.zeros(shape=arr.shape)\n",
    "\n",
    "file  = \"example_data/interaction_network.txt\"\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "with open(file, \"w\") as f:\n",
    "    f.write(f\"ig:#0 {' '.join(map(str, zeroes.flatten()))}\\n\")\n",
    "    f.write(f\"ig:#1 {' '.join(map(str, arr.flatten()))}\\n\")"
   ],
   "id": "7c157d528650ce6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ENES, EXPLORE%, and INFEASIBLE%\n",
    "\n",
    "Finally, only the \"odd one out\" indicators are left. These are ENES, EXPLORE%, and INFEASIBLE%. For INFEASIBLE% we need to write to file, the others are simple enough to verify."
   ],
   "id": "bcd9aed19d6247f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:18.442930Z",
     "start_time": "2024-09-18T11:06:18.438295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f_percent = random.choices(population=range(0,100) ,k=10)\n",
    "f_data = np.column_stack((range(0,10), f_percent))\n",
    "np.savetxt(f\"example_data/f_percent.csv\", f_data, delimiter=\",\", header=f\"iteration,f_percent\", comments=\"\", fmt=\"%.4f\")\n",
    "INFEASIBLE_Percent = sum(f_percent)/len(f_percent)\n",
    "\n",
    "total_iterations = 10\n",
    "iterations_before_target = 9 # this is a lie, doesn't matter\n",
    "fitness_evaluations_before_target = iterations_before_target * 5 \n",
    "global_best_fitness = 0\n",
    "ENES = fitness_evaluations_before_target / iterations_before_target\n",
    "EXPLORE_percent = np.mean(diversity_y / max(diversity_y) * 100)\n",
    "\n",
    "file  = \"example_data/metadata.json\"\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "with open(file, \"w\") as f:\n",
    "    f.write(\"{\" + f'\"total_iterations\": {total_iterations}, \"iterations_before_target\":{iterations_before_target}, \"fitness_evaluations_before_target\": {fitness_evaluations_before_target}, \"global_best_fitness\": {global_best_fitness}, \"solution_index\": {solution_index}' + \"}\")"
   ],
   "id": "6789ae262e51dacd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tests",
   "id": "ee1d47ae6b02cd0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:18.915250Z",
     "start_time": "2024-09-18T11:06:18.910665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k = MemoisedIndicators(path=\"example_data/\")\n",
    "\n",
    "def close_enough(expected, real):\n",
    "    assert round(expected, 4) == round(real,4)"
   ],
   "id": "fa651bf451c57efc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:19.592936Z",
     "start_time": "2024-09-18T11:06:19.186532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "close_enough(DRoC_A, k.get_DRoC_A())\n",
    "close_enough(DRoC_B, k.get_DRoC_B())\n",
    "close_enough(ERT_Diversity, k.get_ERT_Diversity())\n",
    "close_enough(Critical_Diversity, k.get_Critical_Diversity())\n",
    "\n",
    "close_enough(FRoC_A, k.get_FRoC_A())\n",
    "close_enough(FRoC_B, k.get_FRoC_B())\n",
    "close_enough(ERT_Fitness, k.get_ERT_Fitness())\n",
    "close_enough(Critical_Fitness, k.get_Critical_Fitness())\n",
    "\n",
    "close_enough(SRoC_A, k.get_SRoC_A())\n",
    "close_enough(SRoC_B, k.get_SRoC_B())\n",
    "close_enough(ERT_Separation, k.get_ERT_Separation())\n",
    "close_enough(Critical_Separation, k.get_Critical_Separation())\n",
    "\n",
    "close_enough(MRoC_A, k.get_MRoC_A())\n",
    "close_enough(MRoC_B, k.get_MRoC_B())\n",
    "close_enough(ERT_Mobility, k.get_ERT_Mobility())\n",
    "close_enough(Critical_Mobility, k.get_Critical_Mobility())"
   ],
   "id": "ae514d5e896d2193",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:19.602465Z",
     "start_time": "2024-09-18T11:06:19.593845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "close_enough(ntotal, k.get_ntotal())\n",
    "close_enough(nbest, k.get_nbest())\n",
    "close_enough(nshared, k.get_nshared())\n",
    "close_enough(best_strength, k.get_best_strength())"
   ],
   "id": "7e920710875b0361",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:19.807508Z",
     "start_time": "2024-09-18T11:06:19.800196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "close_enough(MID, k.get_MID())\n",
    "close_enough(MGC, k.get_MGC())\n",
    "close_enough(SNID, k.get_SNID())"
   ],
   "id": "187231719053341e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:06:20.272673Z",
     "start_time": "2024-09-18T11:06:20.266759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "close_enough(ENES, k.get_ENES())\n",
    "close_enough(EXPLORE_percent, k.get_EXPLORE_Percent())\n",
    "close_enough(INFEASIBLE_Percent, k.get_INFEASIBLE_Percent())"
   ],
   "id": "3e2d0a54352d438a",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
